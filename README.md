# ğŸ¤– Lift-os-LLM - AI-Native Content Analysis Microservice

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://hub.docker.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **Production-ready microservice for LLM-powered content analysis, optimization, and AI surfacing**

A comprehensive API service that leverages Large Language Models to analyze content, optimize for AI search engines, and provide intelligent recommendations for maximum AI visibility.

## ğŸš€ **Quick Start**

### **Option 1: Docker Deployment (Recommended)**
```bash
git clone https://github.com/daleparr/Lift-os-LLM.git
cd Lift-os-LLM
cp .env.example .env  # Configure your API keys
docker-compose up -d
```

### **Option 2: Local Development**
```bash
git clone https://github.com/daleparr/Lift-os-LLM.git
cd Lift-os-LLM
pip install -r requirements.txt
cp .env.example .env  # Configure your API keys
python -m uvicorn src.main:app --reload
```

### **Option 3: One-Command Setup**
```bash
git clone https://github.com/daleparr/Lift-os-LLM.git
cd Lift-os-LLM
python scripts/setup.py  # Automated setup with dependency installation
```

## ğŸ¯ **Key Features**

### ğŸ§  **LLM-Powered Analysis**
- **Multi-Model Support**: OpenAI, Anthropic, HuggingFace (7,000+ models)
- **Content Intelligence**: Deep semantic analysis and understanding
- **AI Surfacing Scores**: 6-dimension scoring for AI search optimization
- **Cross-Domain Analysis**: Finance, Education, Retail, Healthcare expertise

### ğŸ”§ **Content Optimization**
- **AI Search Optimization**: Perplexity, SGE, Amazon AI compatibility
- **Structured Data Generation**: Schema.org, JSON-LD, Open Graph
- **Meta Tag Enhancement**: SEO and AI-native search optimization
- **Knowledge Graph Analysis**: Entity relationships and semantic context

### ğŸš€ **Production-Ready API**
- **FastAPI Framework**: High-performance async API with auto-documentation
- **JWT Authentication**: Secure token-based authentication
- **Rate Limiting**: Configurable request throttling
- **Comprehensive Monitoring**: Health checks, metrics, and observability

### ğŸ¤– **Advanced AI Capabilities**
- **Vector Embeddings**: Semantic similarity and content matching
- **Batch Processing**: High-throughput content analysis
- **Model Fine-tuning**: Custom model training and optimization
- **Multi-Agent Workflows**: Sophisticated content processing pipelines

## ğŸ“Š **API Endpoints**

### **Core Analysis**
- `POST /api/v1/analyze` - Comprehensive content analysis with AI scoring
- `POST /api/v1/optimize` - Generate optimized content for AI visibility
- `POST /api/v1/embeddings` - Vector embeddings and semantic analysis
- `POST /api/v1/knowledge-graph` - Entity extraction and relationship mapping

### **Batch Operations**
- `POST /api/v1/batch/analyze` - Bulk content analysis with queue management
- `GET /api/v1/batch/status/{job_id}` - Check batch job status and results

### **Model Management**
- `POST /api/v1/models/evaluate` - Compare model performance
- `POST /api/v1/models/finetune` - Submit fine-tuning jobs
- `GET /api/v1/models/available` - List available models and capabilities

### **Monitoring**
- `GET /health` - Service health check
- `GET /ready` - Readiness probe
- `GET /metrics` - Prometheus metrics
- `GET /docs` - Interactive API documentation

## ğŸ—ï¸ **Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Lift-os-LLM API Gateway                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Authentication â”‚ Rate Limiting â”‚ Validation â”‚ Monitoring  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   Analysis Services                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Content     â”‚ â”‚ LLM         â”‚ â”‚ Vector      â”‚ â”‚ Model  â”‚ â”‚
â”‚  â”‚ Analysis    â”‚ â”‚ Orchestratorâ”‚ â”‚ Embeddings  â”‚ â”‚ Managerâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚ Knowledge   â”‚ â”‚ Optimizationâ”‚                           â”‚
â”‚  â”‚ Graph       â”‚ â”‚ Engine      â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Redis Cache    â”‚    PostgreSQL  â”‚    Pinecone Vector   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ **Project Structure**

```
lift-os-llm/
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ ğŸ“‚ api/                 # FastAPI routes and endpoints
â”‚   â”‚   â”œâ”€â”€ v1/
â”‚   â”‚   â”‚   â”œâ”€â”€ analysis.py
â”‚   â”‚   â”‚   â”œâ”€â”€ optimization.py
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”‚   â””â”€â”€ batch.py
â”‚   â”‚   â””â”€â”€ middleware/
â”‚   â”œâ”€â”€ ğŸ“‚ services/            # Core business logic
â”‚   â”‚   â”œâ”€â”€ content_analysis.py
â”‚   â”‚   â”œâ”€â”€ llm_orchestrator.py
â”‚   â”‚   â”œâ”€â”€ vector_embeddings.py
â”‚   â”‚   â”œâ”€â”€ knowledge_graph.py
â”‚   â”‚   â””â”€â”€ optimization_engine.py
â”‚   â”œâ”€â”€ ğŸ“‚ models/              # Data models and schemas
â”‚   â”‚   â”œâ”€â”€ requests.py
â”‚   â”‚   â”œâ”€â”€ responses.py
â”‚   â”‚   â””â”€â”€ entities.py
â”‚   â”œâ”€â”€ ğŸ“‚ core/                # Core utilities and config
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ security.py
â”‚   â”‚   â”œâ”€â”€ database.py
â”‚   â”‚   â””â”€â”€ logging.py
â”‚   â””â”€â”€ main.py                 # FastAPI application entry point
â”œâ”€â”€ ğŸ“‚ tests/
â”‚   â”œâ”€â”€ ğŸ“‚ unit/                # Unit tests
â”‚   â”œâ”€â”€ ğŸ“‚ integration/         # Integration tests
â”‚   â””â”€â”€ ğŸ“‚ fixtures/            # Test data and mocks
â”œâ”€â”€ ğŸ“‚ scripts/                 # Utility and deployment scripts
â”‚   â”œâ”€â”€ setup.py                # Automated setup script
â”‚   â”œâ”€â”€ deploy.sh               # Deployment automation
â”‚   â””â”€â”€ migrate.py              # Database migration
â”œâ”€â”€ ğŸ“‚ .github/workflows/       # CI/CD pipeline
â”œâ”€â”€ ğŸ“‚ config/                  # Configuration files
â”œâ”€â”€ ğŸ³ Dockerfile               # Multi-stage container build
â”œâ”€â”€ ğŸ³ docker-compose.yml       # Production stack
â”œâ”€â”€ ğŸ³ docker-compose.dev.yml   # Development stack
â”œâ”€â”€ ğŸ“‹ requirements.txt         # Python dependencies
â”œâ”€â”€ ğŸ“‹ pyproject.toml           # Project configuration
â”œâ”€â”€ ğŸ“ README.md                # This file
â”œâ”€â”€ ğŸ¤ CONTRIBUTING.md          # Contribution guidelines
â”œâ”€â”€ âš–ï¸ LICENSE                  # MIT License
â””â”€â”€ ğŸ”’ .env.example             # Environment template
```

## ğŸ”§ **Configuration**

### **Required Environment Variables**
```bash
# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4

# Authentication
JWT_SECRET_KEY=your-secret-key
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30

# LLM Providers (choose one or more)
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
HUGGINGFACE_API_TOKEN=hf_...

# Vector Database
PINECONE_API_KEY=...
PINECONE_ENVIRONMENT=us-west1-gcp

# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/liftos_llm
REDIS_URL=redis://localhost:6379

# Monitoring
LOG_LEVEL=INFO
ENABLE_METRICS=true
```

## ğŸš€ **Usage Examples**

### **Content Analysis**
```python
import requests

# Analyze content for AI surfacing
response = requests.post(
    "http://localhost:8000/api/v1/analyze",
    headers={"Authorization": "Bearer YOUR_JWT_TOKEN"},
    json={
        "content": {
            "title": "Premium Wireless Headphones",
            "description": "High-quality audio experience...",
            "url": "https://example.com/product/123"
        },
        "options": {
            "include_embeddings": True,
            "include_knowledge_graph": True,
            "analysis_depth": "comprehensive"
        }
    }
)

result = response.json()
print(f"AI Surfacing Score: {result['ai_surfacing_score']['overall']}")
```

### **Content Optimization**
```python
# Generate optimized content
response = requests.post(
    "http://localhost:8000/api/v1/optimize",
    headers={"Authorization": "Bearer YOUR_JWT_TOKEN"},
    json={
        "original_content": {
            "html": "<html>...</html>",
            "url": "https://example.com/product/123"
        },
        "optimization_targets": [
            "schema_markup",
            "meta_tags",
            "semantic_clarity",
            "ai_search_compatibility"
        ]
    }
)

optimized = response.json()
print(f"Score Improvement: +{optimized['improvements']['score_increase']} points")
```

### **Batch Processing**
```python
# Submit batch analysis job
response = requests.post(
    "http://localhost:8000/api/v1/batch/analyze",
    headers={"Authorization": "Bearer YOUR_JWT_TOKEN"},
    json={
        "urls": [
            "https://example.com/product/1",
            "https://example.com/product/2",
            "https://example.com/product/3"
        ],
        "options": {
            "analysis_type": "comprehensive",
            "priority": "normal"
        }
    }
)

job_id = response.json()["job_id"]
print(f"Batch job submitted: {job_id}")
```

## ğŸ”’ **Security Features**

### **Authentication & Authorization**
- JWT token-based authentication
- Role-based access control (RBAC)
- API key management for service-to-service communication
- Rate limiting per user/IP address

### **Security Hardening**
- Input validation and sanitization
- SQL injection prevention
- XSS protection
- CORS configuration
- Security headers (HSTS, CSP, etc.)

### **Data Protection**
- Encryption in transit (TLS 1.3)
- Secure secrets management
- No persistent storage of sensitive content
- GDPR compliance ready

## ğŸ“Š **Performance & Scaling**

### **Performance Metrics**
- **Response Time**: < 2 seconds (95th percentile)
- **Throughput**: 1000+ requests per minute
- **Concurrent Processing**: Configurable worker pools
- **Cache Hit Rate**: 80%+ for repeated analyses

### **Scaling Options**
- **Horizontal Scaling**: Load balancer ready
- **Auto-scaling**: Kubernetes HPA support
- **Resource Optimization**: Intelligent caching and batching
- **Multi-region Deployment**: Global distribution support

## ğŸ§ª **Testing**

### **Run Tests**
```bash
# Unit tests
pytest tests/unit/ -v

# Integration tests
pytest tests/integration/ -v

# All tests with coverage
pytest --cov=src --cov-report=html

# Load testing
locust -f tests/load/locustfile.py --host=http://localhost:8000
```

### **Test Coverage**
- **Unit Tests**: Individual component testing
- **Integration Tests**: API endpoint testing
- **Load Tests**: Performance and stress testing
- **Security Tests**: Vulnerability scanning

## ğŸ³ **Docker Deployment**

### **Development**
```bash
# Start development stack
docker-compose -f docker-compose.dev.yml up -d

# View logs
docker-compose logs -f api

# Access API
curl http://localhost:8000/health
```

### **Production**
```bash
# Start production stack
docker-compose up -d

# Scale API instances
docker-compose up --scale api=3

# Monitor resources
docker stats
```

## ğŸ“š **Documentation**

### **API Documentation**
- **Interactive Docs**: http://localhost:8000/docs (Swagger UI)
- **ReDoc**: http://localhost:8000/redoc (Alternative documentation)
- **OpenAPI Spec**: http://localhost:8000/openapi.json

### **Additional Resources**
- **[Contributing Guide](CONTRIBUTING.md)**: Development and contribution guidelines
- **[API Reference](docs/api-reference.md)**: Detailed endpoint documentation
- **[Deployment Guide](docs/deployment.md)**: Production deployment instructions
- **[Architecture Guide](docs/architecture.md)**: System design and components

## ğŸ¤ **Contributing**

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### **Development Setup**
```bash
# Clone repository
git clone https://github.com/daleparr/Lift-os-LLM.git
cd Lift-os-LLM

# Install dependencies
pip install -r requirements-dev.txt
pip install -e .

# Set up pre-commit hooks
pre-commit install

# Run tests
pytest
```

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ **Acknowledgments**

- **FastAPI** for the high-performance web framework
- **HuggingFace** for the transformers library and model hub
- **OpenAI & Anthropic** for LLM API access
- **Pinecone** for vector database capabilities
- **Previous Lift OS Surfacing** for architectural patterns

---

**â­ Star this repository if you find it useful!**

**ğŸ”— [API Documentation](http://localhost:8000/docs) | [Contributing](CONTRIBUTING.md) | [Deployment Guide](docs/deployment.md)**
